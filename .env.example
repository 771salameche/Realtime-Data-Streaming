# ==============================================================================
# REAL-TIME DATA STREAMING PIPELINE - ENVIRONMENT CONFIGURATION
# ==============================================================================
# Copy this file to .env and update the values according to your environment
# WARNING: Never commit .env file to version control - it contains sensitive data
# ==============================================================================

# ==============================================================================
# GENERAL CONFIGURATION
# ==============================================================================
ENVIRONMENT=development
PROJECT_NAME=realtime-streaming-pipeline
LOG_LEVEL=INFO
DEBUG=false
TIMEZONE=UTC

# Network Configuration
COMPOSE_PROJECT_NAME=streaming-pipeline
DOCKER_HOST_IP=localhost

# ==============================================================================
# DATABASE CONFIGURATIONS
# ==============================================================================

# PostgreSQL (Airflow Metadata DB)
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=airflow
POSTGRES_USER=airflow
POSTGRES_PASSWORD=your_postgres_password_here
POSTGRES_SCHEMA=public
POSTGRES_CONNECTION_POOL_SIZE=10
POSTGRES_MAX_OVERFLOW=20

# Cassandra Configuration
CASSANDRA_HOST=cassandra
CASSANDRA_PORT=9042
CASSANDRA_KEYSPACE=streaming_data
CASSANDRA_USERNAME=cassandra
CASSANDRA_PASSWORD=your_cassandra_password_here
CASSANDRA_REPLICATION_FACTOR=1
CASSANDRA_CONSISTENCY_LEVEL=ONE
CASSANDRA_CONNECTION_TIMEOUT=30
CASSANDRA_REQUEST_TIMEOUT=30

# Redis (Optional - for caching)
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password_here
REDIS_DB=0
REDIS_CONNECTION_POOL_SIZE=10

# ==============================================================================
# APACHE KAFKA CONFIGURATION
# ==============================================================================

# Kafka Broker Settings
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
KAFKA_EXTERNAL_PORT=9093
KAFKA_INTERNAL_PORT=9092
KAFKA_BROKER_ID=1
KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093

# Kafka Topics Configuration
KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
KAFKA_DELETE_TOPIC_ENABLE=true
KAFKA_NUM_PARTITIONS=6
KAFKA_DEFAULT_REPLICATION_FACTOR=1
KAFKA_MIN_INSYNC_REPLICAS=1

# Kafka Performance Settings
KAFKA_LOG_RETENTION_HOURS=168
KAFKA_LOG_RETENTION_BYTES=1073741824
KAFKA_LOG_SEGMENT_BYTES=104857600
KAFKA_LOG_CLEANUP_POLICY=delete
KAFKA_COMPRESSION_TYPE=snappy

# Kafka Producer Settings
KAFKA_PRODUCER_ACKS=1
KAFKA_PRODUCER_RETRIES=3
KAFKA_PRODUCER_BATCH_SIZE=16384
KAFKA_PRODUCER_LINGER_MS=10
KAFKA_PRODUCER_BUFFER_MEMORY=33554432

# Kafka Consumer Settings
KAFKA_CONSUMER_GROUP_ID=streaming-pipeline-consumers
KAFKA_CONSUMER_AUTO_OFFSET_RESET=earliest
KAFKA_CONSUMER_ENABLE_AUTO_COMMIT=true
KAFKA_CONSUMER_SESSION_TIMEOUT_MS=30000
KAFKA_CONSUMER_MAX_POLL_RECORDS=500

# Kafka Security (if using SASL/SSL)
KAFKA_SECURITY_PROTOCOL=PLAINTEXT
KAFKA_SASL_MECHANISM=PLAIN
KAFKA_SASL_USERNAME=
KAFKA_SASL_PASSWORD=
KAFKA_SSL_KEYSTORE_LOCATION=
KAFKA_SSL_KEYSTORE_PASSWORD=
KAFKA_SSL_TRUSTSTORE_LOCATION=
KAFKA_SSL_TRUSTSTORE_PASSWORD=

# ==============================================================================
# ZOOKEEPER CONFIGURATION
# ==============================================================================
ZOOKEEPER_CLIENT_PORT=2181
ZOOKEEPER_TICK_TIME=2000
ZOOKEEPER_INIT_LIMIT=5
ZOOKEEPER_SYNC_LIMIT=2
ZOOKEEPER_MAX_CLIENT_CONNECTIONS=60

# ==============================================================================
# APACHE SPARK CONFIGURATION
# ==============================================================================

# Spark Master Configuration
SPARK_MASTER_HOST=spark-master
SPARK_MASTER_PORT=7077
SPARK_MASTER_WEBUI_PORT=8081
SPARK_MASTER_OPTS="-Dspark.deploy.defaultCores=2"

# Spark Worker Configuration
SPARK_WORKER_CORES=2
SPARK_WORKER_MEMORY=2g
SPARK_WORKER_PORT=8881
SPARK_WORKER_WEBUI_PORT=8082
SPARK_WORKER_INSTANCES=2

# Spark Application Settings
SPARK_APP_NAME=streaming-data-processor
SPARK_DRIVER_MEMORY=1g
SPARK_DRIVER_CORES=1
SPARK_EXECUTOR_MEMORY=2g
SPARK_EXECUTOR_CORES=2
SPARK_EXECUTOR_INSTANCES=2
SPARK_DEFAULT_PARALLELISM=8

# Spark Streaming Configuration
SPARK_STREAMING_BATCH_DURATION=5
SPARK_STREAMING_CHECKPOINT_LOCATION=/opt/spark/checkpoints
SPARK_STREAMING_GRACEFUL_SHUTDOWN_TIMEOUT=30

# Spark SQL Configuration
SPARK_SQL_ADAPTIVE_ENABLED=true
SPARK_SQL_ADAPTIVE_COALESCE_PARTITIONS_ENABLED=true
SPARK_SQL_WAREHOUSE_DIR=/opt/spark/warehouse
SPARK_SERIALIZER=org.apache.spark.serializer.KryoSerializer

# Spark Monitoring
SPARK_METRICS_NAMESPACE=streaming_pipeline
SPARK_EVENTLOG_ENABLED=true
SPARK_EVENTLOG_DIR=/opt/spark/logs
SPARK_HISTORY_FS_LOGDIRECTORY=/opt/spark/logs

# ==============================================================================
# APACHE AIRFLOW CONFIGURATION
# ==============================================================================

# Airflow Core Settings
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:your_postgres_password_here@postgres:5432/airflow
AIRFLOW__CORE__FERNET_KEY=your_fernet_key_here_generate_using_python_cryptography
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
AIRFLOW__CORE__LOAD_EXAMPLES=false
AIRFLOW__CORE__DEFAULT_TIMEZONE=UTC

# Airflow Web Server
AIRFLOW__WEBSERVER__EXPOSE_CONFIG=false
AIRFLOW__WEBSERVER__AUTHENTICATE=true
AIRFLOW__WEBSERVER__AUTH_BACKEND=airflow.auth.backends.password_auth
AIRFLOW__WEBSERVER__SECRET_KEY=your_webserver_secret_key_here
AIRFLOW__WEBSERVER__WEB_SERVER_PORT=8080
AIRFLOW__WEBSERVER__BASE_URL=http://localhost:8080

# Airflow Scheduler
AIRFLOW__SCHEDULER__SCHEDULE_AFTER_TASK_EXECUTION=true
AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=300
AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT=false
AIRFLOW__SCHEDULER__MAX_THREADS=2

# Airflow Celery (if using CeleryExecutor)
AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/1
AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:your_postgres_password_here@postgres:5432/airflow
AIRFLOW__CELERY__WORKER_CONCURRENCY=4

# Airflow Email Configuration
AIRFLOW__SMTP__SMTP_HOST=smtp.gmail.com
AIRFLOW__SMTP__SMTP_STARTTLS=true
AIRFLOW__SMTP__SMTP_SSL=false
AIRFLOW__SMTP__SMTP_PORT=587
AIRFLOW__SMTP__SMTP_USER=your_email@gmail.com
AIRFLOW__SMTP__SMTP_PASSWORD=your_app_password_here
AIRFLOW__SMTP__SMTP_MAIL_FROM=your_email@gmail.com

# Airflow Logging
AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
AIRFLOW__LOGGING__FAB_LOGGING_LEVEL=WARN
AIRFLOW__LOGGING__REMOTE_LOGGING=false

# ==============================================================================
# CONFLUENT PLATFORM (KAFKA ECOSYSTEM)
# ==============================================================================

# Schema Registry
SCHEMA_REGISTRY_HOST=schema-registry
SCHEMA_REGISTRY_PORT=8081
SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=kafka:9092
SCHEMA_REGISTRY_HOST_NAME=schema-registry
SCHEMA_REGISTRY_LISTENERS=http://0.0.0.0:8081

# Confluent Control Center
CONTROL_CENTER_BOOTSTRAP_SERVERS=kafka:9092
CONTROL_CENTER_ZOOKEEPER_CONNECT=zookeeper:2181
CONTROL_CENTER_SCHEMA_REGISTRY_URL=http://schema-registry:8081
CONTROL_CENTER_REPLICATION_FACTOR=1
CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS=1
CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS=1
CONTROL_CENTER_METRICS_TOPIC_REPLICATION=1
CONTROL_CENTER_PORT=9021

# Kafka Connect (if using)
KAFKA_CONNECT_BOOTSTRAP_SERVERS=kafka:9092
KAFKA_CONNECT_REST_ADVERTISED_HOST_NAME=kafka-connect
KAFKA_CONNECT_REST_PORT=8083
KAFKA_CONNECT_GROUP_ID=compose-connect-group
KAFKA_CONNECT_CONFIG_STORAGE_TOPIC=docker-connect-configs
KAFKA_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1
KAFKA_CONNECT_OFFSET_STORAGE_TOPIC=docker-connect-offsets
KAFKA_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1
KAFKA_CONNECT_STATUS_STORAGE_TOPIC=docker-connect-status
KAFKA_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1

# ==============================================================================
# MONITORING AND OBSERVABILITY
# ==============================================================================

# Prometheus Configuration
PROMETHEUS_PORT=9090
PROMETHEUS_RETENTION_TIME=15d
PROMETHEUS_SCRAPE_INTERVAL=15s

# Grafana Configuration
GRAFANA_PORT=3000
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=your_grafana_password_here
GRAFANA_ALLOW_SIGN_UP=false
GRAFANA_DISABLE_GRAVATAR=true

# JMX Monitoring
JMX_ENABLED=true
JMX_PORT=9999
KAFKA_JMX_PORT=9991
SPARK_JMX_PORT=9992
CASSANDRA_JMX_PORT=9993

# Application Monitoring
METRICS_ENABLED=true
METRICS_PORT=8888
HEALTH_CHECK_INTERVAL=30
ALERT_WEBHOOK_URL=your_slack_webhook_url_here

# ==============================================================================
# EXTERNAL API CONFIGURATIONS
# ==============================================================================

# Data Source APIs
WEATHER_API_KEY=your_weather_api_key_here
WEATHER_API_URL=https://api.openweathermap.org/data/2.5
WEATHER_API_RATE_LIMIT=60

STOCK_API_KEY=your_stock_api_key_here
STOCK_API_URL=https://api.example.com/v1
STOCK_API_RATE_LIMIT=100

NEWS_API_KEY=your_news_api_key_here
NEWS_API_URL=https://newsapi.org/v2
NEWS_API_RATE_LIMIT=1000

# Social Media APIs
TWITTER_API_KEY=your_twitter_api_key_here
TWITTER_API_SECRET=your_twitter_api_secret_here
TWITTER_ACCESS_TOKEN=your_twitter_access_token_here
TWITTER_ACCESS_TOKEN_SECRET=your_twitter_access_token_secret_here
TWITTER_BEARER_TOKEN=your_twitter_bearer_token_here

# Cloud Storage
AWS_ACCESS_KEY_ID=your_aws_access_key_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here
AWS_DEFAULT_REGION=us-east-1
AWS_S3_BUCKET=your-data-bucket

AZURE_STORAGE_ACCOUNT=your_azure_storage_account
AZURE_STORAGE_KEY=your_azure_storage_key
AZURE_CONTAINER_NAME=data-container

GCP_PROJECT_ID=your-gcp-project-id
GCP_SERVICE_ACCOUNT_KEY_PATH=/path/to/service-account-key.json
GCS_BUCKET_NAME=your-gcs-bucket

# ==============================================================================
# SECURITY CONFIGURATION
# ==============================================================================

# JWT Configuration
JWT_SECRET_KEY=your_jwt_secret_key_here
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# API Security
API_RATE_LIMIT_PER_MINUTE=100
API_MAX_REQUEST_SIZE=10MB
CORS_ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080

# SSL/TLS Configuration
SSL_ENABLED=false
SSL_CERT_PATH=/path/to/cert.pem
SSL_KEY_PATH=/path/to/key.pem
SSL_CA_PATH=/path/to/ca.pem

# ==============================================================================
# PERFORMANCE TUNING
# ==============================================================================

# Connection Pools
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=30
REDIS_POOL_SIZE=10
KAFKA_POOL_SIZE=10

# Memory Settings
JAVA_HEAP_SIZE=2g
PYTHON_MEMORY_LIMIT=2g
NODE_MEMORY_LIMIT=1g

# Timeouts
HTTP_TIMEOUT=30
DATABASE_TIMEOUT=30
KAFKA_TIMEOUT=30
SPARK_TIMEOUT=300

# ==============================================================================
# BACKUP AND RECOVERY
# ==============================================================================

# Backup Configuration
BACKUP_ENABLED=true
BACKUP_SCHEDULE=0 2 * * *
BACKUP_RETENTION_DAYS=7
BACKUP_LOCATION=/backups

# Data Retention
DATA_RETENTION_DAYS=30
LOG_RETENTION_DAYS=7
CHECKPOINT_RETENTION_HOURS=72

# ==============================================================================
# DEVELOPMENT/TESTING CONFIGURATION
# ==============================================================================

# Testing
TESTING=false
TEST_DATABASE_URL=postgresql://test_user:test_pass@localhost:5433/test_db
MOCK_EXTERNAL_APIS=false

# Development
DEV_MODE=false
HOT_RELOAD=false
DEBUG_SPARK_UI=true
ENABLE_QUERY_LOGGING=false

# Sample Data
GENERATE_SAMPLE_DATA=false
SAMPLE_DATA_RATE=100
SAMPLE_DATA_DURATION=3600

# ==============================================================================
# CUSTOM APPLICATION SETTINGS
# ==============================================================================

# Business Logic Configuration
MAX_CONCURRENT_STREAMS=10
BATCH_SIZE=1000
PROCESSING_WINDOW_SECONDS=60
ALERT_THRESHOLD=1000

# Data Quality
ENABLE_DATA_VALIDATION=true
SCHEMA_VALIDATION_STRICT=false
NULL_VALUE_THRESHOLD=0.1
DUPLICATE_DETECTION=true

# Machine Learning (if applicable)
ML_MODEL_PATH=/models
ML_MODEL_VERSION=v1.0
ML_BATCH_PREDICTION=true
ML_REAL_TIME_SCORING=false

# ==============================================================================
# NOTES
# ==============================================================================
# 1. Replace all placeholder values (your_*_here) with actual values
# 2. Generate strong passwords and keys for production environments
# 3. Use environment-specific values for different deployment stages
# 4. Consider using secrets management tools for sensitive data
# 5. Regularly rotate passwords and API keys
# 6. Never commit the actual .env file to version control
# ==============================================================================